{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D4uP22VY9w6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c845f6d-cecf-4c48-bfd3-41129d6953ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.stem import PorterStemmer\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "from string import punctuation\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Input,Dense,LSTM\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import concatenate,Flatten,Embedding,Dropout\n",
        "from keras import Model\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "import pickle\n",
        "import joblib\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fn1(df):\n",
        "  #df = df.drop(['id', 'location'] , axis = 1)\n",
        "\n",
        "  def clean_text(text):\n",
        "  \n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"  \",\"\",text)\n",
        "    \"\"\"Removing website and HTML tags and punctiation\"\"\"\n",
        "    text = re.sub(r\"www\" , \"\", text)\n",
        "    text = re.sub(r\"com\" , \"\", text)\n",
        "    text = re.sub(r\"http\" , \"\", text)\n",
        "    text = re.sub(r\"https\" , \"\", text)\n",
        "    text = re.sub(r\"&amp\" , \"\", text)\n",
        "    #text = re.sub(r\"??\" , \"\", text)\n",
        "    text = re.sub(r\"-()\\\"#/@;:<>{}`+=~|.!?,\", \"\", text)\n",
        "  \n",
        "    return text\n",
        "\n",
        "  def stopword_removal(text):\n",
        "      stop = [i for i in stopwords.words(\"english\") if i != \"not\"]\n",
        "      words = []\n",
        "      for i in text.split():\n",
        "        if i not in stop:\n",
        "          words.append(i)\n",
        "      return \" \".join(words)\n",
        "\n",
        "  def stem(text):\n",
        "      return ' '.join([PorterStemmer().stem(i) for i in text.split()])\n",
        "\n",
        "  for i in range(len(df.text)):\n",
        "    df.iloc[i , 1] = clean_text(df.iloc[i , 1])\n",
        "    df.iloc[i , 1] = stopword_removal(df.iloc[i , 1])\n",
        "    df.iloc[i , 1] = stem(df.iloc[i , 1])\n",
        "  \n",
        "  df['keyword'].replace('', np.nan, inplace=True)\n",
        "  df.dropna(subset=['keyword'], inplace=True)\n",
        "  \n",
        "  with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "  \n",
        "  tokenized  = tokenizer.texts_to_sequences(df.text)\n",
        "  train_padded = pad_sequences(tokenized, maxlen = 50  , padding='post' )\n",
        "\n",
        "  enc = joblib.load('enc.pkl')\n",
        "  keyword = enc.transform(df['keyword'].values.reshape(-1,1))\n",
        "\n",
        "  model = keras.models.load_model(\"my_h5_model.h5\")\n",
        "\n",
        "  pred = model.predict([train_padded ,    keyword] )\n",
        "  return pred , df.target"
      ],
      "metadata": {
        "id": "AcL8AGs594LT"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Twitter_processed.csv\")\n",
        "x = df.iloc[ 6500: , 1:]\n",
        "\n",
        "pred , y = fn1(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCnLk77SpTyS",
        "outputId": "3cd31f37-76d9-489c-a9e1-7a2d4dfd98fd"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X is unseen data"
      ],
      "metadata": {
        "id": "gnhmgbQ-T8Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred)):\n",
        "  if pred[i][0] >= 0.5:\n",
        "    pred[i][0] = 1\n",
        "  else:\n",
        "    pred[i][0] = 0"
      ],
      "metadata": {
        "id": "b1B3D0rBSz10"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y = df.target\n",
        "print(\"Acuracy\", round(accuracy_score(y, pred),2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHPiFU7ZUkVY",
        "outputId": "91d4936c-8bee-4e5b-eaa0-d627412f08a6"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acuracy 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fn2(df):\n",
        "  pred , y = fn1(df)\n",
        "  for i in range(len(pred)):\n",
        "    if pred[i][0] >= 0.5:\n",
        "      pred[i][0] = 1\n",
        "    else:\n",
        "      pred[i][0] = 0\n",
        "  #y = df.target\n",
        "  print(\"Acuracy\", round(accuracy_score(y, pred),2))\n"
      ],
      "metadata": {
        "id": "WRfx6ffvKyNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fn2(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKj5sVm8VPYT",
        "outputId": "73d3674c-963a-4b2d-89d9-513e79e6d251"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 1s 35ms/step\n",
            "Acuracy 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EzH15vR5QsPk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}